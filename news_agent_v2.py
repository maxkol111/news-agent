#!/usr/bin/env python3
"""
–ù–û–í–û–°–¢–ù–û–ô –ê–ì–ï–ù–¢ V2.0
–ü–æ–ª–Ω–æ—Å—Ç—å—é –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–π - –±–µ–∑ –≤–Ω–µ—à–Ω–∏—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –∫—Ä–æ–º–µ Ollama
"""

import os
import sys
import json
import sqlite3
import requests
import feedparser
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
import hashlib
import re

class NewsAgentV2:
    """–ê–≤—Ç–æ–Ω–æ–º–Ω—ã–π –Ω–æ–≤–æ—Å—Ç–Ω–æ–π –∞–≥–µ–Ω—Ç —Å SQLite –±–∞–∑–æ–π"""
    
    def __init__(self, model_name: str = "llama3.1:8b"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
        
        Args:
            model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ Ollama
        """
        print("=" * 70)
        print("ü§ñ –ê–í–¢–û–ù–û–ú–ù–´–ô –ù–û–í–û–°–¢–ù–û–ô –ê–ì–ï–ù–¢ v2.0")
        print("=" * 70)
        
        self.model_name = model_name
        self.ollama_url = "http://localhost:11434"
        self.db_file = "news_agent_v2.db"
        self.session = requests.Session()
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
        self.settings = {
            "rss_sources": [
                ("https://lenta.ru/rss/news", "–õ–µ–Ω—Ç–∞.—Ä—É"),
                ("https://ria.ru/export/rss2/index.xml", "–†–ò–ê –ù–æ–≤–æ—Å—Ç–∏"),
                ("https://tass.ru/rss/v2.xml", "–¢–ê–°–°"),
                ("https://www.rbc.ru/rssfeed/newsline.rss", "–†–ë–ö"),
            ],
            "categories": {
                "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏": ["–∏–∏", "–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç", "ai", "–Ω–µ–π—Ä–æ—Å–µ—Ç—å", "—á–∞—Ç", "gpt", "–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ", "it"],
                "–ø–æ–ª–∏—Ç–∏–∫–∞": ["–ø—É—Ç–∏–Ω", "–ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–æ", "—Å—à–∞", "—É–∫—Ä–∞–∏–Ω", "—Å–∞–Ω–∫—Ü–∏", "–≤—ã–±–æ—Ä—ã", "–ø–æ–ª–∏—Ç–∏–∫–∞"],
                "—ç–∫–æ–Ω–æ–º–∏–∫–∞": ["—Ä—É–±–ª—å", "–¥–æ–ª–ª–∞—Ä", "–±–∏—Ä–∂–∞", "–∏–Ω—Ñ–ª—è—Ü–∏—è", "—ç–∫–æ–Ω–æ–º–∏–∫–∞", "—Ä—ã–Ω–æ–∫", "–∫—Ä–∏–∑–∏—Å"],
                "–Ω–∞—É–∫–∞": ["–Ω–∞—É–∫–∞", "–æ—Ç–∫—Ä—ã—Ç–∏–µ", "–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ", "—É—á–µ–Ω—ã–µ", "–∫–æ—Å–º–æ—Å", "–º–µ–¥–∏—Ü–∏–Ω–∞"],
                "—Å–ø–æ—Ä—Ç": ["—Å–ø–æ—Ä—Ç", "—Ñ—É—Ç–±–æ–ª", "—Ö–æ–∫–∫–µ–π", "—á–µ–º–ø–∏–æ–Ω–∞—Ç", "–æ–ª–∏–º–ø–∏–∞–¥–∞"],
            }
        }
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        self._init_database()
        self._check_ollama()
        
        print(f"\n‚úÖ –ê–≥–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω:")
        print(f"   ‚Ä¢ –ú–æ–¥–µ–ª—å: {self.model_name}")
        print(f"   ‚Ä¢ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: {self.db_file}")
        print(f"   ‚Ä¢ –ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤ RSS: {len(self.settings['rss_sources'])}")
    
    def _init_database(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö SQLite"""
        self.conn = sqlite3.connect(self.db_file, check_same_thread=False)
        self.conn.row_factory = sqlite3.Row
        self.cursor = self.conn.cursor()
        
        # –¢–∞–±–ª–∏—Ü–∞ –Ω–æ–≤–æ—Å—Ç–µ–π
        self.cursor.execute('''
            CREATE TABLE IF NOT EXISTS news (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                hash TEXT UNIQUE,
                title TEXT NOT NULL,
                content TEXT,
                summary TEXT,
                source TEXT,
                url TEXT,
                category TEXT,
                keywords TEXT,
                importance REAL DEFAULT 0.5,
                published TEXT,
                collected_at TEXT,
                analyzed_at TEXT
            )
        ''')
        
        # –¢–∞–±–ª–∏—Ü–∞ –∞–Ω–∞–ª–∏–∑–æ–≤
        self.cursor.execute('''
            CREATE TABLE IF NOT EXISTS analyses (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                query TEXT NOT NULL,
                analysis TEXT,
                keywords TEXT,
                sources_used TEXT,
                created_at TEXT
            )
        ''')
        
        # –¢–∞–±–ª–∏—Ü–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        self.cursor.execute('''
            CREATE TABLE IF NOT EXISTS stats (
                date TEXT PRIMARY KEY,
                news_collected INTEGER DEFAULT 0,
                news_analyzed INTEGER DEFAULT 0,
                analyses_made INTEGER DEFAULT 0
            )
        ''')
        
        # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
        self.cursor.execute('CREATE INDEX IF NOT EXISTS idx_news_title ON news(title)')
        self.cursor.execute('CREATE INDEX IF NOT EXISTS idx_news_category ON news(category)')
        self.cursor.execute('CREATE INDEX IF NOT EXISTS idx_news_published ON news(published)')
        
        self.conn.commit()
        
        # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É –Ω–∞—Å—Ç—Ä–æ–µ–∫ –µ—Å–ª–∏ –µ–µ –Ω–µ—Ç
        self.cursor.execute('''
            CREATE TABLE IF NOT EXISTS settings (
                key TEXT PRIMARY KEY,
                value TEXT
            )
        ''')
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        self.cursor.execute('''
            INSERT OR REPLACE INTO settings (key, value)
            VALUES ('model_name', ?)
        ''', (self.model_name,))
        
        self.conn.commit()
        print("üíæ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
    
    def _check_ollama(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Ollama"""
        print("\n1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Ollama...")
        
        try:
            response = self.session.get(f"{self.ollama_url}/api/tags", timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                models = data.get("models", [])
                
                if models:
                    print(f"   ‚úÖ Ollama –¥–æ—Å—Ç—É–ø–µ–Ω (–º–æ–¥–µ–ª–µ–π: {len(models)})")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω—É–∂–Ω—É—é –º–æ–¥–µ–ª—å
                    model_names = [m.get("name", "") for m in models]
                    
                    if self.model_name in model_names:
                        print(f"   ‚úÖ –ú–æ–¥–µ–ª—å '{self.model_name}' –¥–æ—Å—Ç—É–ø–Ω–∞")
                    else:
                        print(f"   ‚ö†Ô∏è  –ú–æ–¥–µ–ª—å '{self.model_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                        available = ", ".join(model_names[:3])
                        print(f"   –î–æ—Å—Ç—É–ø–Ω—ã–µ: {available}...")
                        
                        # –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º –≤—ã–±—Ä–∞—Ç—å –¥—Ä—É–≥—É—é
                        if "llama3.1" in available.lower():
                            for name in model_names:
                                if "llama3.1" in name.lower():
                                    self.model_name = name
                                    print(f"   –ò—Å–ø–æ–ª—å–∑—É—é: {self.model_name}")
                                    break
                        elif model_names:
                            self.model_name = model_names[0]
                            print(f"   –ò—Å–ø–æ–ª—å–∑—É—é –ø–µ—Ä–≤—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é: {self.model_name}")
                else:
                    print("   ‚ö†Ô∏è  –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π")
                    print("   üîß –°–∫–∞—á–∞–π—Ç–µ –º–æ–¥–µ–ª—å: ollama pull llama3.1:8b")
            else:
                print(f"   ‚ùå –û—à–∏–±–∫–∞ HTTP: {response.status_code}")
                
        except requests.exceptions.ConnectionError:
            print("   ‚ùå –ù–µ —É–¥–∞–µ—Ç—Å—è –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Ollama")
            print("   üîß –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ Ollama –∑–∞–ø—É—â–µ–Ω: ollama serve")
            sys.exit(1)
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞: {e}")
            sys.exit(1)
    
    def _generate_hash(self, text: str) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ö—ç—à–∞ –¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω–æ–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        return hashlib.md5(text.encode()).hexdigest()
    
    def _categorize_text(self, text: str) -> str:
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞"""
        text_lower = text.lower()
        
        for category, keywords in self.settings["categories"].items():
            for keyword in keywords:
                if keyword in text_lower:
                    return category
        
        return "—Ä–∞–∑–Ω–æ–µ"
    
    def _calculate_importance(self, title: str, source: str, category: str) -> float:
        """–†–∞—Å—á–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç–∏ —Å—Ç–∞—Ç—å–∏ (0.0 - 1.0)"""
        score = 0.0
        
        # –í–µ—Å –∏—Å—Ç–æ—á–Ω–∏–∫–∞
        source_weights = {
            "–†–ò–ê –ù–æ–≤–æ—Å—Ç–∏": 0.8,
            "–¢–ê–°–°": 0.8,
            "–õ–µ–Ω—Ç–∞.—Ä—É": 0.7,
            "–†–ë–ö": 0.6,
        }
        score += source_weights.get(source, 0.5)
        
        # –í–∞–∂–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ
        important_words = [
            "–ø—É—Ç–∏–Ω", "–≤–æ–π–Ω–∞", "–∫—Ä–∏–∑–∏—Å", "—Å—à–∞", "–∫–∏—Ç–∞–π", 
            "–ø—Ä–æ—Ä—ã–≤", "—Ä–µ–≤–æ–ª—é—Ü–∏—è", "–∫–∞—Ç–∞—Å—Ç—Ä–æ—Ñ–∞", "—Ç–µ—Ä–∞–∫—Ç"
        ]
        title_lower = title.lower()
        for word in important_words:
            if word in title_lower:
                score += 0.2
                break
        
        # –ö–∞—Ç–µ–≥–æ—Ä–∏—è
        category_weights = {
            "–ø–æ–ª–∏—Ç–∏–∫–∞": 0.3,
            "—ç–∫–æ–Ω–æ–º–∏–∫–∞": 0.2,
            "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏": 0.2,
            "–Ω–∞—É–∫–∞": 0.1,
        }
        score += category_weights.get(category, 0.0)
        
        return min(score, 1.0)
    
    def call_llm(self, prompt: str, max_tokens: int = 500) -> str:
        """
        –í—ã–∑–æ–≤ —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ Ollama API
        
        Args:
            prompt: –ó–∞–ø—Ä–æ—Å
            max_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
            
        Returns:
            –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏
        """
        try:
            url = f"{self.ollama_url}/api/generate"
            
            payload = {
                "model": self.model_name,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.2,
                    "num_predict": max_tokens,
                    "top_k": 40,
                    "top_p": 0.9,
                }
            }
            
            response = self.session.post(url, json=payload, timeout=120)
            
            if response.status_code == 200:
                data = response.json()
                response_text = data.get("response", "").strip()
                
                # –û—á–∏—Å—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
                response_text = re.sub(r'\n+', '\n', response_text).strip()
                return response_text
            else:
                error_msg = f"–û—à–∏–±–∫–∞ API ({response.status_code})"
                if response.status_code == 404:
                    error_msg += " - –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
                print(f"‚ùå {error_msg}")
                return f"[–û—à–∏–±–∫–∞: {error_msg}]"
                
        except requests.exceptions.Timeout:
            print("‚ùå –¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞ –∫ –º–æ–¥–µ–ª–∏")
            return "[–û—à–∏–±–∫–∞: –¢–∞–π–º–∞—É—Ç]"
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–∑–æ–≤–∞ LLM: {e}")
            return f"[–û—à–∏–±–∫–∞: {str(e)}]"
    
    def summarize_text(self, text: str, max_length: int = 150) -> str:
        """
        –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
        
        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            max_length: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Ä–µ–∑—é–º–µ
            
        Returns:
            –ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ
        """
        if len(text) < 50:
            return text
        
        prompt = f"""–°–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ —Ç–µ–∫—Å—Ç–∞ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è):

–¢–ï–ö–°–¢:
{text[:800]}

–†–ï–ó–Æ–ú–ï:"""
        
        summary = self.call_llm(prompt, max_tokens=100)
        return summary[:max_length]
    
    def extract_keywords(self, text: str, max_keywords: int = 5) -> List[str]:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        
        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            max_keywords: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
            
        Returns:
            –°–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        """
        if len(text) < 20:
            return []
        
        prompt = f"""–ò–∑–≤–ª–µ–∫–∏ {max_keywords} –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏–ª–∏ —Ñ—Ä–∞–∑ –∏–∑ —Ç–µ–∫—Å—Ç–∞.
–í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ —Å–ª–æ–≤–∞ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é, –±–µ–∑ –æ–±—ä—è—Å–Ω–µ–Ω–∏–π.

–¢–ï–ö–°–¢:
{text[:500]}

–ö–õ–Æ–ß–ï–í–´–ï –°–õ–û–í–ê:"""
        
        response = self.call_llm(prompt, max_tokens=100)
        
        # –ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞
        keywords = []
        for item in response.split(','):
            item = item.strip()
            if item and len(item) > 1:
                keywords.append(item)
        
        return keywords[:max_keywords]
    
    def collect_news(self, limit_per_source: int = 3):
        """
        –°–±–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ RSS-–ª–µ–Ω—Ç
        
        Args:
            limit_per_source: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤–æ—Å—Ç–µ–π —Å –∫–∞–∂–¥–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
        """
        print(f"\nüì∞ –°–ë–û–† –ù–û–í–û–°–¢–ï–ô")
        print("-" * 60)
        
        total_collected = 0
        
        for rss_url, source_name in self.settings["rss_sources"]:
            try:
                print(f"üì° {source_name}...")
                feed = feedparser.parse(rss_url)
                
                if not feed.entries:
                    print(f"   ‚ö†Ô∏è  –ù–µ—Ç —Å—Ç–∞—Ç–µ–π –≤ –ª–µ–Ω—Ç–µ")
                    continue
                
                source_collected = 0
                
                for entry in feed.entries[:limit_per_source]:
                    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π —Ö—ç—à
                    article_hash = self._generate_hash(
                        f"{entry.get('link', '')}{entry.get('title', '')}"
                    )
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ —Ç–∞–∫–∞—è —Å—Ç–∞—Ç—å—è
                    self.cursor.execute(
                        "SELECT id FROM news WHERE hash = ?", 
                        (article_hash,)
                    )
                    if self.cursor.fetchone():
                        continue
                    
                    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                    title = entry.get('title', '–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞').strip()
                    content = entry.get('summary', entry.get('description', '')).strip()
                    url = entry.get('link', '')
                    published = entry.get('published', datetime.now().isoformat())
                    category = self._categorize_text(title)
                    
                    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –≤–∞–∂–Ω–æ—Å—Ç—å
                    importance = self._calculate_importance(title, source_name, category)
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–∑—É
                    self.cursor.execute('''
                        INSERT INTO news 
                        (hash, title, content, source, url, category, importance, published, collected_at)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                    ''', (
                        article_hash,
                        title,
                        content,
                        source_name,
                        url,
                        category,
                        importance,
                        published,
                        datetime.now().isoformat()
                    ))
                    
                    source_collected += 1
                    total_collected += 1
                    
                    print(f"   ‚úì {title[:50]}...")
                
                print(f"   üìä –°–æ–±—Ä–∞–Ω–æ: {source_collected} —Å—Ç–∞—Ç–µ–π")
                
            except Exception as e:
                print(f"   ‚ùå –û—à–∏–±–∫–∞: {e}")
        
        self.conn.commit()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        today = datetime.now().strftime("%Y-%m-%d")
        self.cursor.execute('''
            INSERT OR REPLACE INTO stats (date, news_collected)
            VALUES (?, COALESCE((SELECT news_collected FROM stats WHERE date = ?), 0) + ?)
        ''', (today, today, total_collected))
        self.conn.commit()
        
        print(f"\n‚úÖ –ò–¢–û–ì–û —Å–æ–±—Ä–∞–Ω–æ: {total_collected} –Ω–æ–≤—ã—Ö —Å—Ç–∞—Ç–µ–π")
    
    def analyze_news_articles(self, limit: int = 5):
        """
        –ê–Ω–∞–ª–∏–∑ –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π
        
        Args:
            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        """
        print(f"\nüîç –ê–ù–ê–õ–ò–ó –ù–û–í–û–°–¢–ï–ô")
        print("-" * 60)
        
        # –ü–æ–ª—É—á–∞–µ–º –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏
        self.cursor.execute('''
            SELECT id, title, content, source, category
            FROM news 
            WHERE analyzed_at IS NULL 
            ORDER BY importance DESC, published DESC 
            LIMIT ?
        ''', (limit,))
        
        articles = self.cursor.fetchall()
        
        if not articles:
            print("   ‚ÑπÔ∏è  –ù–µ—Ç –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π")
            return
        
        print(f"   –ù–∞–π–¥–µ–Ω–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {len(articles)} —Å—Ç–∞—Ç–µ–π")
        
        analyzed_count = 0
        
        for article in articles:
            try:
                article_id, title, content, source, category = article
                
                print(f"   üìÑ –ê–Ω–∞–ª–∏–∑: {title[:40]}...")
                
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∑—é–º–µ
                summary = self.summarize_text(f"{title}. {content}")
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
                keywords = self.extract_keywords(f"{title} {content}")
                keywords_str = ", ".join(keywords)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å –≤ –±–∞–∑–µ
                self.cursor.execute('''
                    UPDATE news 
                    SET summary = ?, keywords = ?, analyzed_at = ?
                    WHERE id = ?
                ''', (
                    summary,
                    keywords_str,
                    datetime.now().isoformat(),
                    article_id
                ))
                
                analyzed_count += 1
                
                # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                import time
                time.sleep(1)
                
            except Exception as e:
                print(f"   ‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç–∞—Ç—å–∏: {e}")
        
        self.conn.commit()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        today = datetime.now().strftime("%Y-%m-%d")
        self.cursor.execute('''
            INSERT OR REPLACE INTO stats (date, news_analyzed)
            VALUES (?, COALESCE((SELECT news_analyzed FROM stats WHERE date = ?), 0) + ?)
        ''', (today, today, analyzed_count))
        self.conn.commit()
        
        print(f"\n‚úÖ –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {analyzed_count} —Å—Ç–∞—Ç–µ–π")
    
    def analyze_topic(self, topic: str) -> Dict[str, Any]:
        """
        –ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–º—ã
        
        Args:
            topic: –¢–µ–º–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
        """
        print(f"\nüéØ –ê–ù–ê–õ–ò–ó –¢–ï–ú–´: {topic}")
        print("-" * 60)
        
        start_time = datetime.now()
        
        try:
            # –ò—â–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏
            relevant_news = self.search_news(topic, limit=5)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
            context = ""
            if relevant_news:
                context_lines = []
                for i, news in enumerate(relevant_news[:3], 1):
                    context_lines.append(f"{i}. {news['title']} ({news['source']})")
                    if news.get('summary'):
                        context_lines.append(f"   {news['summary']}")
                context = "\n".join(context_lines)
            
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            prompt = f"""–ü—Ä–æ–≤–µ–¥–∏ –≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–º—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.

–¢–ï–ú–ê –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê: {topic}

–ö–û–ù–¢–ï–ö–°–¢ –ò–ó –ù–û–í–û–°–¢–ï–ô:
{context if context else "–ù–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –≤ –±–∞–∑–µ"}

–°–¢–†–£–ö–¢–£–†–ê –ê–ù–ê–õ–ò–ó–ê:
1. –û–°–ù–û–í–ù–´–ï –ê–°–ü–ï–ö–¢–´ –¢–ï–ú–´
2. –ö–õ–Æ–ß–ï–í–´–ï –§–ê–ö–¢–´ –ò –¢–ï–ù–î–ï–ù–¶–ò–ò  
3. –í–û–ó–ú–û–ñ–ù–´–ï –ü–†–ò–ß–ò–ù–´ –ò –°–õ–ï–î–°–¢–í–ò–Ø
4. –ü–ï–†–°–ü–ï–ö–¢–ò–í–´ –ò –ü–†–û–ì–ù–û–ó–´
5. –í–´–í–û–î–´ –ò –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò

–ê–ù–ê–õ–ò–ó:"""
            
            print("ü§î –ú–æ–¥–µ–ª—å –ø—Ä–æ–≤–æ–¥–∏—Ç –∞–Ω–∞–ª–∏–∑...")
            analysis = self.call_llm(prompt, max_tokens=1000)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –∞–Ω–∞–ª–∏–∑–∞
            keywords = self.extract_keywords(analysis)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑ –≤ –±–∞–∑—É
            self.cursor.execute('''
                INSERT INTO analyses (query, analysis, keywords, sources_used, created_at)
                VALUES (?, ?, ?, ?, ?)
            ''', (
                topic,
                analysis,
                json.dumps(keywords, ensure_ascii=False),
                str(len(relevant_news)),
                datetime.now().isoformat()
            ))
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            today = datetime.now().strftime("%Y-%m-%d")
            self.cursor.execute('''
                INSERT OR REPLACE INTO stats (date, analyses_made)
                VALUES (?, COALESCE((SELECT analyses_made FROM stats WHERE date = ?), 0) + 1)
            ''', (today, today))
            
            self.conn.commit()
            
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            
            result = {
                "topic": topic,
                "analysis": analysis,
                "keywords": keywords,
                "relevant_news_count": len(relevant_news),
                "analysis_time_seconds": round(duration, 2),
                "success": True,
                "timestamp": end_time.isoformat()
            }
            
            print(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {duration:.1f} —Å–µ–∫—É–Ω–¥")
            print(f"üìä –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –Ω–æ–≤–æ—Å—Ç–µ–π: {len(relevant_news)}")
            print(f"üîë –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {', '.join(keywords[:5])}")
            
            return result
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}")
            
            return {
                "topic": topic,
                "error": str(e),
                "success": False,
                "timestamp": datetime.now().isoformat()
            }
    
    def search_news(self, query: str, limit: int = 10) -> List[Dict[str, Any]]:
        """
        –ü–æ–∏—Å–∫ –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ –∑–∞–ø—Ä–æ—Å—É
        
        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            
        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π
        """
        try:
            # –ü—Ä–æ—Å—Ç–æ–π –ø–æ–ª–Ω–æ—Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫ –≤ SQLite
            query_lower = query.lower()
            
            self.cursor.execute('''
                SELECT title, content, summary, source, url, category, keywords, published
                FROM news 
                WHERE LOWER(title) LIKE ? 
                   OR LOWER(content) LIKE ? 
                   OR LOWER(category) LIKE ?
                   OR LOWER(keywords) LIKE ?
                ORDER BY importance DESC, published DESC
                LIMIT ?
            ''', (
                f'%{query_lower}%',
                f'%{query_lower}%',
                f'%{query_lower}%',
                f'%{query_lower}%',
                limit
            ))
            
            results = []
            for row in self.cursor.fetchall():
                results.append({
                    "title": row[0],
                    "content": row[1],
                    "summary": row[2],
                    "source": row[3],
                    "url": row[4],
                    "category": row[5],
                    "keywords": row[6],
                    "published": row[7]
                })
            
            return results
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
            return []
    
    def get_statistics(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        
        Returns:
            –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        """
        try:
            # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            self.cursor.execute("SELECT COUNT(*) FROM news")
            total_news = self.cursor.fetchone()[0]
            
            self.cursor.execute("SELECT COUNT(*) FROM news WHERE analyzed_at IS NOT NULL")
            analyzed_news = self.cursor.fetchone()[0]
            
            self.cursor.execute("SELECT COUNT(*) FROM analyses")
            total_analyses = self.cursor.fetchone()[0]
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
            self.cursor.execute('''
                SELECT category, COUNT(*) as count
                FROM news
                GROUP BY category
                ORDER BY count DESC
            ''')
            categories = {}
            for row in self.cursor.fetchall():
                categories[row[0]] = row[1]
            
            # –ü–æ—Å–ª–µ–¥–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–∏
            self.cursor.execute('''
                SELECT title, source, published
                FROM news
                ORDER BY published DESC
                LIMIT 3
            ''')
            recent_news = []
            for row in self.cursor.fetchall():
                recent_news.append({
                    "title": row[0][:50] + "..." if len(row[0]) > 50 else row[0],
                    "source": row[1],
                    "published": row[2][:10] if row[2] else "N/A"
                })
            
            return {
                "status": "ready",
                "model": self.model_name,
                "statistics": {
                    "total_news": total_news,
                    "analyzed_news": analyzed_news,
                    "total_analyses": total_analyses,
                    "analysis_coverage": f"{(analyzed_news/total_news*100):.1f}%" if total_news > 0 else "0%",
                    "categories": categories,
                },
                "recent_news": recent_news,
                "database_size_mb": os.path.getsize(self.db_file) / (1024 * 1024) if os.path.exists(self.db_file) else 0,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                "status": "error",
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }


# ============================================================================
# –¢–ï–†–ú–ò–ù–ê–õ–¨–ù–´–ô –ò–ù–¢–ï–†–§–ï–ô–°
# ============================================================================

def clear_screen():
    """–û—á–∏—Å—Ç–∫–∞ —ç–∫—Ä–∞–Ω–∞"""
    os.system('cls' if os.name == 'nt' else 'clear')

def print_header(text: str):
    """–ü–µ—á–∞—Ç—å –∑–∞–≥–æ–ª–æ–≤–∫–∞"""
    print("\n" + "=" * 60)
    print(f"üì∞ {text}")
    print("=" * 60)

def run_test_mode():
    """–†–µ–∂–∏–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    clear_screen()
    print_header("–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ê–ì–ï–ù–¢–ê")
    
    try:
        print("1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞...")
        agent = NewsAgentV2()
        
        print("\n2. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞...")
        stats = agent.get_statistics()
        print(f"   ‚Ä¢ –ú–æ–¥–µ–ª—å: {stats['model']}")
        print(f"   ‚Ä¢ –ù–æ–≤–æ—Å—Ç–µ–π –≤ –±–∞–∑–µ: {stats['statistics']['total_news']}")
        print(f"   ‚Ä¢ –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {stats['statistics']['analyzed_news']}")
        print(f"   ‚Ä¢ –ê–Ω–∞–ª–∏–∑–æ–≤ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ: {stats['statistics']['total_analyses']}")
        
        print("\n3. –¢–µ—Å—Ç –≤—ã–∑–æ–≤–∞ –º–æ–¥–µ–ª–∏...")
        test_response = agent.call_llm("–ü—Ä–∏–≤–µ—Ç! –û—Ç–≤–µ—Ç—å –æ–¥–Ω–∏–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º.", max_tokens=50)
        print(f"   –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏: {test_response}")
        
        print("\n4. –¢–µ—Å—Ç —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏...")
        test_text = "–£—á–µ–Ω—ã–µ —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–ª–∏ –Ω–æ–≤—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ –¥–ª—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏."
        summary = agent.summarize_text(test_text)
        print(f"   –†–µ–∑—é–º–µ: {summary}")
        
        print("\n5. –¢–µ—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤...")
        keywords = agent.extract_keywords(test_text)
        print(f"   –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {', '.join(keywords)}")
        
        input("\nüéØ –ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è...")
        
        print_header("–°–ë–û–† –ò –ê–ù–ê–õ–ò–ó –ù–û–í–û–°–¢–ï–ô")
        
        print("\n6. –°–±–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π (—Ç–µ—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º)...")
        agent.collect_news(limit_per_source=2)
        
        print("\n7. –ê–Ω–∞–ª–∏–∑ —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π...")
        agent.analyze_news_articles(limit=2)
        
        print("\n8. –¢–µ—Å—Ç–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–º—ã...")
        result = agent.analyze_topic("–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç")
        
        if result["success"]:
            print(f"\n   ‚úÖ –ê–Ω–∞–ª–∏–∑ —É—Å–ø–µ—à–µ–Ω!")
            print(f"   ‚è±Ô∏è  –í—Ä–µ–º—è: {result['analysis_time_seconds']} —Å–µ–∫")
            print(f"   üîë –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {', '.join(result['keywords'][:5])}")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–∞—á–∞–ª–æ –∞–Ω–∞–ª–∏–∑–∞
            if result["analysis"]:
                lines = result["analysis"].split('\n')[:10]
                print(f"\n   üìä –ù–∞—á–∞–ª–æ –∞–Ω–∞–ª–∏–∑–∞:")
                for line in lines:
                    if line.strip():
                        print(f"   {line}")
        else:
            print(f"   ‚ùå –û—à–∏–±–∫–∞: {result.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")
        
        print_header("–§–ò–ù–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
        final_stats = agent.get_statistics()
        print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        print(f"   ‚Ä¢ –í—Å–µ–≥–æ –Ω–æ–≤–æ—Å—Ç–µ–π: {final_stats['statistics']['total_news']}")
        print(f"   ‚Ä¢ –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {final_stats['statistics']['analyzed_news']}")
        print(f"   ‚Ä¢ –ê–Ω–∞–ª–∏–∑–æ–≤: {final_stats['statistics']['total_analyses']}")
        print(f"   ‚Ä¢ –†–∞–∑–º–µ—Ä –±–∞–∑—ã: {final_stats['database_size_mb']:.2f} MB")
        
        if final_stats['statistics']['categories']:
            print(f"\nüìà –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú:")
            for cat, count in final_stats['statistics']['categories'].items():
                print(f"   ‚Ä¢ {cat}: {count}")
        
        print("\n" + "=" * 60)
        print("‚úÖ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù–û!")
        print("=" * 60)
        
        input("\nüéØ –ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –≤—ã—Ö–æ–¥–∞ –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é...")
        
    except KeyboardInterrupt:
        print("\n\n‚èπÔ∏è  –¢–µ—Å—Ç –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        import traceback
        traceback.print_exc()
        input("\nüéØ –ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è...")

def run_interactive_mode():
    """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã"""
    clear_screen()
    
    try:
        print_header("–ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ê–ì–ï–ù–¢–ê")
        agent = NewsAgentV2()
        
        while True:
            clear_screen()
            print_header("–ì–õ–ê–í–ù–û–ï –ú–ï–ù–Æ")
            
            print("\n–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:")
            print("1. üì∞ –°–æ–±—Ä–∞—Ç—å –Ω–æ–≤–æ—Å—Ç–∏")
            print("2. üîç –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤–æ—Å—Ç–∏")
            print("3. üéØ –ê–Ω–∞–ª–∏–∑ —Ç–µ–º—ã")
            print("4. üîé –ü–æ–∏—Å–∫ –Ω–æ–≤–æ—Å—Ç–µ–π")
            print("5. üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
            print("6. üß™ –¢–µ—Å—Ç –º–æ–¥–µ–ª–∏")
            print("7. üö™ –í—ã—Ö–æ–¥")
            
            choice = input("\n–í–∞—à –≤—ã–±–æ—Ä (1-7): ").strip()
            
            if choice == "1":
                clear_screen()
                print_header("–°–ë–û–† –ù–û–í–û–°–¢–ï–ô")
                limit = input("\n–°–∫–æ–ª—å–∫–æ —Å—Ç–∞—Ç–µ–π —Å –∫–∞–∂–¥–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞? (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 3): ").strip()
                limit = int(limit) if limit.isdigit() else 3
                agent.collect_news(limit_per_source=limit)
                input("\nüéØ –ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è...")
                
            elif choice == "2":
                clear_screen()
                print_header("–ê–ù–ê–õ–ò–ó –ù–û–í–û–°–¢–ï–ô")
                limit = input("\n–°–∫–æ–ª—å–∫–æ –Ω–æ–≤–æ—Å—Ç–µ–π –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å? (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 5): ").strip()
                limit = int(limit) if limit.isdigit() else 5
                agent.analyze_news_articles(limit=limit)
                input("\nüéØ –ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è...")
                
            elif choice == "3":
                clear_screen()
                print_header("–ê–ù–ê–õ–ò–ó –¢–ï–ú–´")
                topic = input("\n–í–≤–µ–¥–∏—Ç–µ —Ç–µ–º—É –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: ").strip()
                if topic:
                    result = agent.analyze_topic(topic)
                    
                    clear_screen()
                    print_header(f"–†–ï–ó–£–õ–¨–¢–ê–¢ –ê–ù–ê–õ–ò–ó–ê: {topic}")
                    
                    if result["success"]:
                        print(f"\nüìä –ò–ù–§–û–†–ú–ê–¶–ò–Ø:")
                        print(f"   ‚è±Ô∏è  –í—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞: {result['analysis_time_seconds']} —Å–µ–∫")
                        print(f"   üì∞ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –Ω–æ–≤–æ—Å—Ç–µ–π: {result['relevant_news_count']}")
                        print(f"   üîë –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {', '.join(result['keywords'][:8])}")
                        
                        print(f"\nüìù –ê–ù–ê–õ–ò–ó:")
                        print("-" * 60)
                        print(result["analysis"])
                        print("-" * 60)
                    else:
                        print(f"\n‚ùå –û—à–∏–±–∫–∞: {result.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")
                    
                    input("\nüéØ –ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è...")
                
            elif choice == "4":
                clear_screen()
                print_header("–ü–û–ò–°–ö –ù–û–í–û–°–¢–ï–ô")
                query = input("\n–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–∏—Å–∫–∞: ").strip()
                if query:
                    results = agent.search_news(query, limit=10)
                    
                    clear_screen()
                    print_header(f"–†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–û–ò–°–ö–ê: '{query}'")
                    print(f"\n–ù–∞–π–¥–µ–Ω–æ: {len(results)} –Ω–æ–≤–æ—Å—Ç–µ–π\n")
                    
                    for i, news in enumerate(results, 1):
                        print(f"{i}. {news['title']}")
                        print(f"   üìç –ò—Å—Ç–æ—á–Ω–∏–∫: {news['source']}")
                        print(f"   üè∑Ô∏è  –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {news['category']}")
                        if news.get('summary'):
                            print(f"   üìù –†–µ–∑—é–º–µ: {news['summary']}")
                        print()
                    
                    input("\nüéØ –ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è...")
                
            elif choice == "5":
                clear_screen()
                print_header("–°–¢–ê–¢–ò–°–¢–ò–ö–ê")
                stats = agent.get_statistics()
                
                print(f"\nüìä –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
                print(f"   ü§ñ –ú–æ–¥–µ–ª—å: {stats['model']}")
                print(f"   üì∞ –í—Å–µ–≥–æ –Ω–æ–≤–æ—Å—Ç–µ–π: {stats['statistics']['total_news']}")
                print(f"   üîç –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {stats['statistics']['analyzed_news']}")
                print(f"   üìà –ü–æ–∫—Ä—ã—Ç–∏–µ –∞–Ω–∞–ª–∏–∑–∞: {stats['statistics']['analysis_coverage']}")
                print(f"   üéØ –í—ã–ø–æ–ª–Ω–µ–Ω–æ –∞–Ω–∞–ª–∏–∑–æ–≤: {stats['statistics']['total_analyses']}")
                print(f"   üíæ –†–∞–∑–º–µ—Ä –±–∞–∑—ã: {stats['database_size_mb']:.2f} MB")
                
                if stats['statistics']['categories']:
                    print(f"\nüìà –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú:")
                    for cat, count in sorted(
                        stats['statistics']['categories'].items(), 
                        key=lambda x: x[1], 
                        reverse=True
                    ):
                        print(f"   ‚Ä¢ {cat}: {count}")
                
                if stats.get('recent_news'):
                    print(f"\nüïê –ü–û–°–õ–ï–î–ù–ò–ï –ù–û–í–û–°–¢–ò:")
                    for news in stats['recent_news'][:3]:
                        print(f"   ‚Ä¢ {news['title']}")
                        print(f"     [{news['source']}, {news['published']}]")
                
                input("\nüéØ –ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è...")
                
            elif choice == "6":
                clear_screen()
                print_header("–¢–ï–°–¢ –ú–û–î–ï–õ–ò")
                test_prompt = input("\n–í–≤–µ–¥–∏—Ç–µ —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å: ").strip()
                if test_prompt:
                    response = agent.call_llm(test_prompt, max_tokens=200)
                    print(f"\nü§ñ –û–¢–í–ï–¢ –ú–û–î–ï–õ–ò:\n{response}\n")
                    input("üéØ –ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è...")
                
            elif choice == "7":
                print("\nüëã –í—ã—Ö–æ–¥ –∏–∑ –ø—Ä–æ–≥—Ä–∞–º–º—ã...")
                break
                
            else:
                print("\n‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")
                input("üéØ –ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è...")
                
    except KeyboardInterrupt:
        print("\n\nüëã –í—ã—Ö–æ–¥ –∏–∑ –ø—Ä–æ–≥—Ä–∞–º–º—ã...")
    except Exception as e:
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        input("\nüéØ –ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –≤—ã—Ö–æ–¥–∞...")

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    clear_screen()
    
    print("=" * 70)
    print("ü§ñ –ù–û–í–û–°–¢–ù–û–ô –ò–ò-–ê–ì–ï–ù–¢ v2.0")
    print("=" * 70)
    print("–ê–≤—Ç–æ–Ω–æ–º–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å SQLite –±–∞–∑–æ–π")
    print("–¢—Ä–µ–±—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ: Python 3.8+, Ollama —Å –º–æ–¥–µ–ª—å—é LLaMA")
    print("=" * 70)
    
    while True:
        print("\n–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã:")
        print("1. üß™ –¢–µ—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ –∑–∞–ø—É—Å–∫–∞)")
        print("2. üí¨ –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º")
        print("3. üö™ –í—ã—Ö–æ–¥")
        
        choice = input("\n–í–∞—à –≤—ã–±–æ—Ä (1-3): ").strip()
        
        if choice == "1":
            run_test_mode()
        elif choice == "2":
            run_interactive_mode()
        elif choice == "3":
            print("\nüëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
            break
        else:
            print("\n‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nüëã –ü—Ä–æ–≥—Ä–∞–º–º–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"\n‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()